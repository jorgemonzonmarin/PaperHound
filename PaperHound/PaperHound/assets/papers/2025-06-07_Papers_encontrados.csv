"Query","Titulo","DOI","Revista","Abstract"
"query1","Magnesium oxide use and reduced risk of dementia: a retrospective, nationwide cohort study in Taiwan","10.1080/03007995.2017.1385449","Scopus","  We have studied the structure of $^4$He droplets doped with magnesium atoms using density functional theory. We have found that the solvation properties of this system strongly depend on the size of the $^4$He droplet. For small drops, Mg resides in a deep surface state, whereas for large size drops it is fully solvated but radially delocalized in their interior. We have studied the $3s3p$ $^1$P$_1 \leftarrow 3s^2$ $^1$S$_0$ transition of the dopant, and have compared our results with experimental data from laser induced fluorescence (LIF). Line broadening effects due to the coupling of dynamical deformations of the surrounding helium with the dipole excitation of the impurity are explicitly taken into account. We show that the Mg radial delocalization inside large droplets may help reconcile the apparently contradictory solvation properties of magnesium as provided by LIF and electron-impact ionization experiments. The structure of $^4$He drops doped with two magnesium atoms is also studied and used to interpret the results of resonant two-photon-ionization (R2PI) and LIF experiments. We have found that the two solvated Mg atoms do not easily merge into a dimer, but rather form a weakly-bound state due to the presence of an energy barrier caused by the helium environment that keep them some 9.5 \AA{} apart, preventing the formation of the Mg$_2$ molecule. From this observation, we suggest that Mg atoms in $^4$He drops may form, under suitable conditions, a soft ``foam''-like aggregate rather than coalesce into a compact metallic cluster. Our findings are in qualitative agreement with recent R2PI experimental evidences. We predict that, contrarily, Mg atoms adsorbed in $^3$He droplets do not form such metastable aggregates. "
"query1","How different is the care of terminal pancreatic cancer patients in inpatient palliative care units and acute hospital wards? A nationwide population-based study Cancer palliative care","10.1186/s12904-016-0075-x","Scopus","  In this paper we introduce novel Virtual Reality (VR) and Augmented Reality (AR) treatments to improve the psychological well being of patients in palliative care, based on interviews with a clinical psychologist who has successfully implemented VR assisted interventions on palliative care patients in the Hong Kong hospital system. Our VR and AR assisted interventions are adaptations of traditional palliative care therapies which simultaneously facilitate patients communication with family and friends while isolated in hospital due to physical weakness and COVID-19 related restrictions. The first system we propose is a networked, metaverse platform for palliative care patients to create customized virtual environments with therapists, family and friends which function as immersive and collaborative versions of 'life review' and 'reminiscence therapy'. The second proposed system will investigate the use of Mixed Reality telepresence and haptic touch in an AR environment, which will allow palliative care patients to physically feel friends and family in a virtual space, adding to the sense of presence and immersion in that environment. "
"query1","The handbook of mites of economic plants: Identification, bio-ecology and control","No disponible","Scopus","  In this paper, we present a mathematical model for the interaction between honey bees and mites. The dynamics of a mite-infested honey bee colony and the evaluation of the commonly used mite-control strategies (traditional, mechanical and chemical) are studied. The mite-free and mite reproduction numbers are derived using the next generation operator approach. The mathematical analysis of the model reveals that in the absence of mites, the colony survives if the mite-free reproduction number is greater than unity otherwise it goes extinct. Stability and sensitivity analyses of the model reveal that the egg laying rate of the queen bee is key in regulating mite reproduction. Adult bee grooming and hygienic behavior of worker bees have also been shown to play a vital role in reducing parasitism. Using the Volterra-Lyapunov stable matrix approach, the mite-infested equilibrium is confirmed to be globally asymptotically stable when the mite-free reproduction number is greater than unity and the mite reproduction number is greater than unity. It is also shown that varroa mite control strategies that focus on limiting mite-reproduction such as caging the queen bee and using a young queen bee quickly reduces the mite reproduction number to a value less than unity compared to those that are intended to kill the mites. "
"query1","Prime Ministers and Rhetorical Governance","No disponible","Scopus","  We give an elementary introduction, through illustrative examples but without proofs, to one of the basic consequences of the Langlands programme, namely the law governing the primes modulo which a given irreducible integral polynomial splits completely. Some recent results, such as the modularity of elliptic curves over the rationals, or the proof of Serre's conjecture by Khare and Wintenberger, are also illustrated through examples. "
"query1","A hierarchical photo visualization system emphasizing temporal and color-based coherences","10.1007/s11042-010-0700-2","Scopus","  In this paper, we propose a novel model with a hierarchical photo-scene encoder and a reconstructor for the task of album storytelling. The photo-scene encoder contains two sub-encoders, namely the photo and scene encoders, which are stacked together and behave hierarchically to fully exploit the structure information of the photos within an album. Specifically, the photo encoder generates semantic representation for each photo while exploiting temporal relationships among them. The scene encoder, relying on the obtained photo representations, is responsible for detecting the scene changes and generating scene representations. Subsequently, the decoder dynamically and attentively summarizes the encoded photo and scene representations to generate a sequence of album representations, based on which a story consisting of multiple coherent sentences is generated. In order to fully extract the useful semantic information from an album, a reconstructor is employed to reproduce the summarized album representations based on the hidden states of the decoder. The proposed model can be trained in an end-to-end manner, which results in an improved performance over the state-of-the-arts on the public visual storytelling (VIST) dataset. Ablation studies further demonstrate the effectiveness of the proposed hierarchical photo-scene encoder and reconstructor. "
"query1","Query optimization in the presence of foreign functions","https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=169376aa8342eae8c0c5eafcf30f3bf32ea4cb49","VLDB","  Query optimization in relational database management systems (DBMSs) is critical for fast query processing. The query optimizer relies on precise selectivity and cost estimates to effectively optimize queries prior to execution. While this strategy is effective for relational DBMSs, it is not sufficient for DBMSs tailored for processing machine learning (ML) queries. In ML-centric DBMSs, query optimization is challenging for two reasons. First, the performance bottleneck of the queries shifts to user-defined functions (UDFs) that often wrap around deep learning models, making it difficult to accurately estimate UDF statistics without profiling the query. This leads to inaccurate statistics and sub-optimal query plans. Second, the optimal query plan for ML queries is data-dependent, necessitating DBMSs to adapt the query plan on the fly during execution. So, a static query plan is not sufficient for such queries.   In this paper, we present Hydro, an ML-centric DBMS that utilizes adaptive query processing (AQP) for efficiently processing ML queries. Hydro is designed to quickly evaluate UDF-based query predicates by ensuring optimal predicate evaluation order and improving the scalability of UDF execution. By integrating AQP, Hydro continuously monitors UDF statistics, routes data to predicates in an optimal order, and dynamically allocates resources for evaluating predicates. We demonstrate Hydro's efficacy through four illustrative use cases, delivering up to 11.52x speedup over a baseline system. "
"query1","Query-based data pricing","https://dl.acm.org/doi/abs/10.1145/2770870","Journal of the ACM …","  We study the price rigidity of regular and sale prices, and how it is affected by pricing formats (pricing strategies). We use data from three large Canadian stores with different pricing formats (Every-Day-Low-Price, Hi-Lo, and Hybrid) that are located within a 1 km radius of each other. Our data contains both the actual transaction prices and actual regular prices as displayed on the store shelves. We combine these data with two generated regular price series (filtered prices and reference prices) and study their rigidity. Regular price rigidity varies with store formats because different format stores treat sale prices differently, and consequently define regular prices differently. Correspondingly, the meanings of price cuts and sale prices vary across store formats. To interpret the findings, we consider the store pricing format distribution across the US. "
"query1","Discrepant and multi-instance proxies for unsupervised person re-identification","http://openaccess.thecvf.com/content/ICCV2023/html/Zou_Discrepant_and_Multi-Instance_Proxies_for_Unsupervised_Person_Re-Identification_ICCV_2023_paper.html","Proceedings of the IEEE …","  We initiate the study of the effects of non-transparency in decision rules on individuals' ability to improve in strategic learning settings. Inspired by real-life settings, such as loan approvals and college admissions, we remove the assumption typically made in the strategic learning literature, that the decision rule is fully known to individuals, and focus instead on settings where it is inaccessible. In their lack of knowledge, individuals try to infer this rule by learning from their peers (e.g., friends and acquaintances who previously applied for a loan), naturally forming groups in the population, each with possibly different type and level of information regarding the decision rule. We show that, in equilibrium, the principal's decision rule optimizing welfare across sub-populations may cause a strong negative externality: the true quality of some of the groups can actually deteriorate. On the positive side, we show that, in many natural cases, optimal improvement can be guaranteed simultaneously for all sub-populations. We further introduce a measure we term information overlap proxy, and demonstrate its usefulness in characterizing the disparity in improvements across sub-populations. Finally, we identify a natural condition under which improvement can be guaranteed for all sub-populations while maintaining high predictive accuracy. We complement our theoretical analysis with experiments on real-world datasets. "
"query1","Stellar-A Library for API Programming","https://msp.cis.strath.ac.uk/types2025/abstracts/TYPES2025_paper77.pdf","NA","  Developers rely on third-party library Application Programming Interfaces (APIs) when developing software. However, libraries typically come with assumptions and API usage constraints, whose violation results in API misuse. API misuses may result in crashes or incorrect behavior. Even though API misuse is a well-studied area, a recent study of API misuse of deep learning libraries showed that the nature of these misuses and their symptoms are different from misuses of traditional libraries, and as a result highlighted potential shortcomings of current misuse detection tools. We speculate that these observations may not be limited to deep learning API misuses but may stem from the data-centric nature of these APIs. Data-centric libraries often deal with diverse data structures, intricate processing workflows, and a multitude of parameters, which can make them inherently more challenging to use correctly. Therefore, understanding the potential misuses of these libraries is important to avoid unexpected application behavior. To this end, this paper contributes an empirical study of API misuses of five data-centric libraries that cover areas such as data processing, numerical computation, machine learning, and visualization. We identify misuses of these libraries by analyzing data from both Stack Overflow and GitHub. Our results show that many of the characteristics of API misuses observed for deep learning libraries extend to misuses of the data-centric library APIs we study. We also find that developers tend to misuse APIs from data-centric libraries, regardless of whether the API directive appears in the documentation. Overall, our work exposes the challenges of API misuse in data-centric libraries, rather than only focusing on deep learning libraries. Our collected misuses and their characterization lay groundwork for future research to help reduce misuses of these libraries. "
"query1","Bab 13. Pernyataan SQL","https://repository.unikom.ac.id/30754/1/pemrograman%20c++%20builder%2013.pdf","NA","  This is a summary of the proof of BAB conjecture. All material are taken from the two BAB paper in the reference. The aim of this summary is to help reader to understand the more technical side of the proof of BAB. "
"query1","The Codling Moth-A Quandray and a Query1","https://doi.org/10.1093/jee/14.2.156","OpenAlex","  Large Language Models (LLMs) have been successfully used in many natural-language tasks and applications including text generation and AI chatbots. They also are a promising new technology for concept-oriented deep learning (CODL). However, the prerequisite is that LLMs understand concepts and ensure conceptual consistency. We discuss these in this paper, as well as major uses of LLMs for CODL including concept extraction from text, concept graph extraction from text, and concept learning. Human knowledge consists of both symbolic (conceptual) knowledge and embodied (sensory) knowledge. Text-only LLMs, however, can represent only symbolic (conceptual) knowledge. Multimodal LLMs, on the other hand, are capable of representing the full range (conceptual and sensory) of human knowledge. We discuss conceptual understanding in visual-language LLMs, the most important multimodal LLMs, and major uses of them for CODL including concept extraction from image, concept graph extraction from image, and concept learning. While uses of LLMs for CODL are valuable standalone, they are particularly valuable as part of LLM applications such as AI chatbots. "
"query1","The Codling Moth-A Quandray and a Query1","10.1093/jee/14.2.156","CrossRef","  Large Language Models (LLMs) have been successfully used in many natural-language tasks and applications including text generation and AI chatbots. They also are a promising new technology for concept-oriented deep learning (CODL). However, the prerequisite is that LLMs understand concepts and ensure conceptual consistency. We discuss these in this paper, as well as major uses of LLMs for CODL including concept extraction from text, concept graph extraction from text, and concept learning. Human knowledge consists of both symbolic (conceptual) knowledge and embodied (sensory) knowledge. Text-only LLMs, however, can represent only symbolic (conceptual) knowledge. Multimodal LLMs, on the other hand, are capable of representing the full range (conceptual and sensory) of human knowledge. We discuss conceptual understanding in visual-language LLMs, the most important multimodal LLMs, and major uses of them for CODL including concept extraction from image, concept graph extraction from image, and concept learning. While uses of LLMs for CODL are valuable standalone, they are particularly valuable as part of LLM applications such as AI chatbots. "
" query2","Cycle-VQA: A Cycle-Consistent Framework for Robust Medical Visual Question Answering","10.1016/j.patcog.2025.111609","Scopus","No abstract available"
" query2","Progress in artificial intelligence assisted digestive endoscopy diagnosis of digestive system diseases","10.11569/wcjd.v32.i3.171","Scopus","  In recent years, the diagnosis of gastrointestinal (GI) diseases has advanced greatly with the advent of high-tech video capsule endoscopy (VCE) technology, which allows for non-invasive observation of the digestive system. The MisaHub Capsule Vision Challenge encourages the development of vendor-independent artificial intelligence models that can autonomously classify GI anomalies from VCE images. This paper presents CNN architecture designed specifically for multiclass classification of ten gut pathologies, including angioectasia, bleeding, erosion, erythema, foreign bodies, lymphangiectasia, polyps, ulcers, and worms as well as their normal state. "
" query2","Data pyramid structure for optimizing EUS-based GISTs diagnosis in multi-center analysis with missing label","10.1016/j.compbiomed.2023.107897","Scopus","  Spatiotemporal traffic time series, such as traffic speed data, collected from sensing systems are often incomplete, with considerable corruption and large amounts of missing values. A vast amount of data conceals implicit data structures, which poses significant challenges for data recovery issues, such as mining the potential spatio-temporal correlations of data and identifying abnormal data. In this paper, we propose a Tucker decomposition-based sparse low-rank high-order tensor optimization model (TSLTO) for data imputation and anomaly diagnosis. We decompose the traffic tensor data into low-rank and sparse tensors, and establish a sparse low-rank high-order tensor optimization model based on Tucker decomposition. By utilizing tools of non-smooth analysis for tensor functions, we explore the optimality conditions of the proposed tensor optimization model and design an ADMM optimization algorithm for solving the model. Finally, numerical experiments are conducted on both synthetic data and a real-world dataset: the urban traffic speed dataset of Guangzhou. Numerical comparisons with several representative existing algorithms demonstrate that our proposed approach achieves higher accuracy and efficiency in traffic flow data recovery and anomaly diagnosis tasks. "
" query2","Query2: Query over queries for improving gastrointestinal stromal tumour detection in an endoscopic ultrasound","10.1016/j.compbiomed.2022.106424","Scopus","No abstract available"
" query2","Probabilistic Occlusion Culling using Confidence Maps for High-Quality Rendering of Large Particle Data","10.1109/TVCG.2021.3114788","Scopus","  Establishing robust and accurate correspondences between a pair of images is a long-standing computer vision problem with numerous applications. While classically dominated by sparse methods, emerging dense approaches offer a compelling alternative paradigm that avoids the keypoint detection step. However, dense flow estimation is often inaccurate in the case of large displacements, occlusions, or homogeneous regions. In order to apply dense methods to real-world applications, such as pose estimation, image manipulation, or 3D reconstruction, it is therefore crucial to estimate the confidence of the predicted matches.   We propose the Enhanced Probabilistic Dense Correspondence Network, PDC-Net+, capable of estimating accurate dense correspondences along with a reliable confidence map. We develop a flexible probabilistic approach that jointly learns the flow prediction and its uncertainty. In particular, we parametrize the predictive distribution as a constrained mixture model, ensuring better modelling of both accurate flow predictions and outliers. Moreover, we develop an architecture and an enhanced training strategy tailored for robust and generalizable uncertainty prediction in the context of self-supervised training. Our approach obtains state-of-the-art results on multiple challenging geometric matching and optical flow datasets. We further validate the usefulness of our probabilistic confidence estimation for the tasks of pose estimation, 3D reconstruction, image-based localization, and image retrieval. Code and models are available at https://github.com/PruneTruong/DenseMatching. "
" query2","Query rewrites with views for XML in DB2","https://ieeexplore.ieee.org/abstract/document/4812535/","2009 IEEE 25th …","  We study the complexity of query answering using views in a probabilistic XML setting, identifying large classes of XPath queries -- with child and descendant navigation and predicates -- for which there are efficient (PTime) algorithms. We consider this problem under the two possible semantics for XML query results: with persistent node identifiers and in their absence. Accordingly, we consider rewritings that can exploit a single view, by means of compensation, and rewritings that can use multiple views, by means of intersection. Since in a probabilistic setting queries return answers with probabilities, the problem of rewriting goes beyond the classic one of retrieving XML answers from views. For both semantics of XML queries, we show that, even when XML answers can be retrieved from views, their probabilities may not be computable. For rewritings that use only compensation, we describe a PTime decision procedure, based on easily verifiable criteria that distinguish between the feasible cases -- when probabilistic XML results are computable -- and the unfeasible ones. For rewritings that can use multiple views, with compensation and intersection, we identify the most permissive conditions that make probabilistic rewriting feasible, and we describe an algorithm that is sound in general, and becomes complete under fairly permissive restrictions, running in PTime modulo worst-case exponential time equivalence tests. This is the best we can hope for since intersection makes query equivalence intractable already over deterministic data. Our algorithm runs in PTime whenever deterministic rewritings can be found in PTime. "
" query2","Query2: Query over queries for improving gastrointestinal stromal tumour detection in an endoscopic ultrasound","https://www.sciencedirect.com/science/article/pii/S0010482522011325","Computers in Biology and …","No abstract available"
" query2","Implementation of two semantic query optimization techniques in DB2 universal database","https://www.researchgate.net/profile/Jarek-Gryz/publication/221309776_Implementation_of_Two_Semantic_Query_Optimization_Techniques_in_DB2_Universal_Database/links/0912f51279e7662532000000/Implementation-of-Two-Semantic-Query-Optimization-Techniques-in-DB2-Universal-Database.pdf","VLDB","  We investigate practical algorithms for inconsistency-tolerant query answering over prioritized knowledge bases, which consist of a logical theory, a set of facts, and a priority relation between conflicting facts. We consider three well-known semantics (AR, IAR and brave) based upon two notions of optimal repairs (Pareto and completion). Deciding whether a query answer holds under these semantics is (co)NP-complete in data complexity for a large class of logical theories, and SAT-based procedures have been devised for repair-based semantics when there is no priority relation, or the relation has a special structure. The present paper introduces the first SAT encodings for Pareto- and completion-optimal repairs w.r.t. general priority relations and proposes several ways of employing existing and new encodings to compute answers under (optimal) repair-based semantics, by exploiting different reasoning modes of SAT solvers. The comprehensive experimental evaluation of our implementation compares both (i) the impact of adopting semantics based on different kinds of repairs, and (ii) the relative performances of alternative procedures for the same semantics. "
" query2","Query 2: The sum of values from a normal and a truncated normal distribution (continued)","https://www.jstor.org/stable/1266101","Technometrics","  Low-resource language translation is a challenging but socially valuable NLP task. Building on recent work adapting the Transformer's normalization to this setting, we propose QKNorm, a normalization technique that modifies the attention mechanism to make the softmax function less prone to arbitrary saturation without sacrificing expressivity. Specifically, we apply $\ell_2$ normalization along the head dimension of each query and key matrix prior to multiplying them and then scale up by a learnable parameter instead of dividing by the square root of the embedding dimension. We show improvements averaging 0.928 BLEU over state-of-the-art bilingual benchmarks for 5 low-resource translation pairs from the TED Talks corpus and IWSLT'15. "
" query2","Processing performance on apache pig, apache hive and MySQL cluster","https://ieeexplore.ieee.org/abstract/document/7010600/","Proceedings of International …","  Huge amounts of data being generated continuously by digitally interconnected systems of humans, organizations and machines. Data comes in variety of formats including structured, unstructured and semi-structured, what makes it impossible to apply the same standard approaches, techniques and algorithms to manage and process this data. Fortunately, the enterprise level distributed platform named Hadoop Ecosystem exists. This paper explores Apache Hive component that provides full stack data managements functionality in terms of Data Definition, Data Manipulation and Data Processing. Hive is a data warehouse system, which works with structured data stored in tables. Since, Hive works on top the Hadoop HDSFS, it benefits from extraordinary feature of HDFS including Fault Tolerance, Reliability, High Availability, Scalability, etc. In addition, Hive can take advantage of distributed computing power of the cluster through assigning jobs to MapReduce, Tez and Spark engines to run complex queries. The paper is focused on studying of Hive Data Model and analysis of processing performance done by MapReduce and Tez. "
"query1","Magnesium oxide use and reduced risk of dementia: a retrospective, nationwide cohort study in Taiwan","10.1080/03007995.2017.1385449","Scopus","  We have studied the structure of $^4$He droplets doped with magnesium atoms using density functional theory. We have found that the solvation properties of this system strongly depend on the size of the $^4$He droplet. For small drops, Mg resides in a deep surface state, whereas for large size drops it is fully solvated but radially delocalized in their interior. We have studied the $3s3p$ $^1$P$_1 \leftarrow 3s^2$ $^1$S$_0$ transition of the dopant, and have compared our results with experimental data from laser induced fluorescence (LIF). Line broadening effects due to the coupling of dynamical deformations of the surrounding helium with the dipole excitation of the impurity are explicitly taken into account. We show that the Mg radial delocalization inside large droplets may help reconcile the apparently contradictory solvation properties of magnesium as provided by LIF and electron-impact ionization experiments. The structure of $^4$He drops doped with two magnesium atoms is also studied and used to interpret the results of resonant two-photon-ionization (R2PI) and LIF experiments. We have found that the two solvated Mg atoms do not easily merge into a dimer, but rather form a weakly-bound state due to the presence of an energy barrier caused by the helium environment that keep them some 9.5 \AA{} apart, preventing the formation of the Mg$_2$ molecule. From this observation, we suggest that Mg atoms in $^4$He drops may form, under suitable conditions, a soft ``foam''-like aggregate rather than coalesce into a compact metallic cluster. Our findings are in qualitative agreement with recent R2PI experimental evidences. We predict that, contrarily, Mg atoms adsorbed in $^3$He droplets do not form such metastable aggregates. "
"query1","How different is the care of terminal pancreatic cancer patients in inpatient palliative care units and acute hospital wards? A nationwide population-based study Cancer palliative care","10.1186/s12904-016-0075-x","Scopus","  In this paper we introduce novel Virtual Reality (VR) and Augmented Reality (AR) treatments to improve the psychological well being of patients in palliative care, based on interviews with a clinical psychologist who has successfully implemented VR assisted interventions on palliative care patients in the Hong Kong hospital system. Our VR and AR assisted interventions are adaptations of traditional palliative care therapies which simultaneously facilitate patients communication with family and friends while isolated in hospital due to physical weakness and COVID-19 related restrictions. The first system we propose is a networked, metaverse platform for palliative care patients to create customized virtual environments with therapists, family and friends which function as immersive and collaborative versions of 'life review' and 'reminiscence therapy'. The second proposed system will investigate the use of Mixed Reality telepresence and haptic touch in an AR environment, which will allow palliative care patients to physically feel friends and family in a virtual space, adding to the sense of presence and immersion in that environment. "
"query1","The handbook of mites of economic plants: Identification, bio-ecology and control","No disponible","Scopus","  In this paper, we present a mathematical model for the interaction between honey bees and mites. The dynamics of a mite-infested honey bee colony and the evaluation of the commonly used mite-control strategies (traditional, mechanical and chemical) are studied. The mite-free and mite reproduction numbers are derived using the next generation operator approach. The mathematical analysis of the model reveals that in the absence of mites, the colony survives if the mite-free reproduction number is greater than unity otherwise it goes extinct. Stability and sensitivity analyses of the model reveal that the egg laying rate of the queen bee is key in regulating mite reproduction. Adult bee grooming and hygienic behavior of worker bees have also been shown to play a vital role in reducing parasitism. Using the Volterra-Lyapunov stable matrix approach, the mite-infested equilibrium is confirmed to be globally asymptotically stable when the mite-free reproduction number is greater than unity and the mite reproduction number is greater than unity. It is also shown that varroa mite control strategies that focus on limiting mite-reproduction such as caging the queen bee and using a young queen bee quickly reduces the mite reproduction number to a value less than unity compared to those that are intended to kill the mites. "
"query1","Prime Ministers and Rhetorical Governance","No disponible","Scopus","  We give an elementary introduction, through illustrative examples but without proofs, to one of the basic consequences of the Langlands programme, namely the law governing the primes modulo which a given irreducible integral polynomial splits completely. Some recent results, such as the modularity of elliptic curves over the rationals, or the proof of Serre's conjecture by Khare and Wintenberger, are also illustrated through examples. "
"query1","A hierarchical photo visualization system emphasizing temporal and color-based coherences","10.1007/s11042-010-0700-2","Scopus","  In this paper, we propose a novel model with a hierarchical photo-scene encoder and a reconstructor for the task of album storytelling. The photo-scene encoder contains two sub-encoders, namely the photo and scene encoders, which are stacked together and behave hierarchically to fully exploit the structure information of the photos within an album. Specifically, the photo encoder generates semantic representation for each photo while exploiting temporal relationships among them. The scene encoder, relying on the obtained photo representations, is responsible for detecting the scene changes and generating scene representations. Subsequently, the decoder dynamically and attentively summarizes the encoded photo and scene representations to generate a sequence of album representations, based on which a story consisting of multiple coherent sentences is generated. In order to fully extract the useful semantic information from an album, a reconstructor is employed to reproduce the summarized album representations based on the hidden states of the decoder. The proposed model can be trained in an end-to-end manner, which results in an improved performance over the state-of-the-arts on the public visual storytelling (VIST) dataset. Ablation studies further demonstrate the effectiveness of the proposed hierarchical photo-scene encoder and reconstructor. "
"query1","Query optimization in the presence of foreign functions","https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=169376aa8342eae8c0c5eafcf30f3bf32ea4cb49","VLDB","  Query optimization in relational database management systems (DBMSs) is critical for fast query processing. The query optimizer relies on precise selectivity and cost estimates to effectively optimize queries prior to execution. While this strategy is effective for relational DBMSs, it is not sufficient for DBMSs tailored for processing machine learning (ML) queries. In ML-centric DBMSs, query optimization is challenging for two reasons. First, the performance bottleneck of the queries shifts to user-defined functions (UDFs) that often wrap around deep learning models, making it difficult to accurately estimate UDF statistics without profiling the query. This leads to inaccurate statistics and sub-optimal query plans. Second, the optimal query plan for ML queries is data-dependent, necessitating DBMSs to adapt the query plan on the fly during execution. So, a static query plan is not sufficient for such queries.   In this paper, we present Hydro, an ML-centric DBMS that utilizes adaptive query processing (AQP) for efficiently processing ML queries. Hydro is designed to quickly evaluate UDF-based query predicates by ensuring optimal predicate evaluation order and improving the scalability of UDF execution. By integrating AQP, Hydro continuously monitors UDF statistics, routes data to predicates in an optimal order, and dynamically allocates resources for evaluating predicates. We demonstrate Hydro's efficacy through four illustrative use cases, delivering up to 11.52x speedup over a baseline system. "
"query1","Query-based data pricing","https://dl.acm.org/doi/abs/10.1145/2770870","Journal of the ACM …","  We study the price rigidity of regular and sale prices, and how it is affected by pricing formats (pricing strategies). We use data from three large Canadian stores with different pricing formats (Every-Day-Low-Price, Hi-Lo, and Hybrid) that are located within a 1 km radius of each other. Our data contains both the actual transaction prices and actual regular prices as displayed on the store shelves. We combine these data with two generated regular price series (filtered prices and reference prices) and study their rigidity. Regular price rigidity varies with store formats because different format stores treat sale prices differently, and consequently define regular prices differently. Correspondingly, the meanings of price cuts and sale prices vary across store formats. To interpret the findings, we consider the store pricing format distribution across the US. "
"query1","Discrepant and multi-instance proxies for unsupervised person re-identification","http://openaccess.thecvf.com/content/ICCV2023/html/Zou_Discrepant_and_Multi-Instance_Proxies_for_Unsupervised_Person_Re-Identification_ICCV_2023_paper.html","Proceedings of the IEEE …","  We initiate the study of the effects of non-transparency in decision rules on individuals' ability to improve in strategic learning settings. Inspired by real-life settings, such as loan approvals and college admissions, we remove the assumption typically made in the strategic learning literature, that the decision rule is fully known to individuals, and focus instead on settings where it is inaccessible. In their lack of knowledge, individuals try to infer this rule by learning from their peers (e.g., friends and acquaintances who previously applied for a loan), naturally forming groups in the population, each with possibly different type and level of information regarding the decision rule. We show that, in equilibrium, the principal's decision rule optimizing welfare across sub-populations may cause a strong negative externality: the true quality of some of the groups can actually deteriorate. On the positive side, we show that, in many natural cases, optimal improvement can be guaranteed simultaneously for all sub-populations. We further introduce a measure we term information overlap proxy, and demonstrate its usefulness in characterizing the disparity in improvements across sub-populations. Finally, we identify a natural condition under which improvement can be guaranteed for all sub-populations while maintaining high predictive accuracy. We complement our theoretical analysis with experiments on real-world datasets. "
"query1","Stellar-A Library for API Programming","https://msp.cis.strath.ac.uk/types2025/abstracts/TYPES2025_paper77.pdf","NA","  Developers rely on third-party library Application Programming Interfaces (APIs) when developing software. However, libraries typically come with assumptions and API usage constraints, whose violation results in API misuse. API misuses may result in crashes or incorrect behavior. Even though API misuse is a well-studied area, a recent study of API misuse of deep learning libraries showed that the nature of these misuses and their symptoms are different from misuses of traditional libraries, and as a result highlighted potential shortcomings of current misuse detection tools. We speculate that these observations may not be limited to deep learning API misuses but may stem from the data-centric nature of these APIs. Data-centric libraries often deal with diverse data structures, intricate processing workflows, and a multitude of parameters, which can make them inherently more challenging to use correctly. Therefore, understanding the potential misuses of these libraries is important to avoid unexpected application behavior. To this end, this paper contributes an empirical study of API misuses of five data-centric libraries that cover areas such as data processing, numerical computation, machine learning, and visualization. We identify misuses of these libraries by analyzing data from both Stack Overflow and GitHub. Our results show that many of the characteristics of API misuses observed for deep learning libraries extend to misuses of the data-centric library APIs we study. We also find that developers tend to misuse APIs from data-centric libraries, regardless of whether the API directive appears in the documentation. Overall, our work exposes the challenges of API misuse in data-centric libraries, rather than only focusing on deep learning libraries. Our collected misuses and their characterization lay groundwork for future research to help reduce misuses of these libraries. "
"query1","Bab 13. Pernyataan SQL","https://repository.unikom.ac.id/30754/1/pemrograman%20c++%20builder%2013.pdf","NA","  This is a summary of the proof of BAB conjecture. All material are taken from the two BAB paper in the reference. The aim of this summary is to help reader to understand the more technical side of the proof of BAB. "
"query1","The Codling Moth-A Quandray and a Query1","https://doi.org/10.1093/jee/14.2.156","OpenAlex","  Large Language Models (LLMs) have been successfully used in many natural-language tasks and applications including text generation and AI chatbots. They also are a promising new technology for concept-oriented deep learning (CODL). However, the prerequisite is that LLMs understand concepts and ensure conceptual consistency. We discuss these in this paper, as well as major uses of LLMs for CODL including concept extraction from text, concept graph extraction from text, and concept learning. Human knowledge consists of both symbolic (conceptual) knowledge and embodied (sensory) knowledge. Text-only LLMs, however, can represent only symbolic (conceptual) knowledge. Multimodal LLMs, on the other hand, are capable of representing the full range (conceptual and sensory) of human knowledge. We discuss conceptual understanding in visual-language LLMs, the most important multimodal LLMs, and major uses of them for CODL including concept extraction from image, concept graph extraction from image, and concept learning. While uses of LLMs for CODL are valuable standalone, they are particularly valuable as part of LLM applications such as AI chatbots. "
"query1","The Codling Moth-A Quandray and a Query1","10.1093/jee/14.2.156","CrossRef","  Large Language Models (LLMs) have been successfully used in many natural-language tasks and applications including text generation and AI chatbots. They also are a promising new technology for concept-oriented deep learning (CODL). However, the prerequisite is that LLMs understand concepts and ensure conceptual consistency. We discuss these in this paper, as well as major uses of LLMs for CODL including concept extraction from text, concept graph extraction from text, and concept learning. Human knowledge consists of both symbolic (conceptual) knowledge and embodied (sensory) knowledge. Text-only LLMs, however, can represent only symbolic (conceptual) knowledge. Multimodal LLMs, on the other hand, are capable of representing the full range (conceptual and sensory) of human knowledge. We discuss conceptual understanding in visual-language LLMs, the most important multimodal LLMs, and major uses of them for CODL including concept extraction from image, concept graph extraction from image, and concept learning. While uses of LLMs for CODL are valuable standalone, they are particularly valuable as part of LLM applications such as AI chatbots. "
" query2","Cycle-VQA: A Cycle-Consistent Framework for Robust Medical Visual Question Answering","10.1016/j.patcog.2025.111609","Scopus","No abstract available"
" query2","Progress in artificial intelligence assisted digestive endoscopy diagnosis of digestive system diseases","10.11569/wcjd.v32.i3.171","Scopus","  In recent years, the diagnosis of gastrointestinal (GI) diseases has advanced greatly with the advent of high-tech video capsule endoscopy (VCE) technology, which allows for non-invasive observation of the digestive system. The MisaHub Capsule Vision Challenge encourages the development of vendor-independent artificial intelligence models that can autonomously classify GI anomalies from VCE images. This paper presents CNN architecture designed specifically for multiclass classification of ten gut pathologies, including angioectasia, bleeding, erosion, erythema, foreign bodies, lymphangiectasia, polyps, ulcers, and worms as well as their normal state. "
" query2","Data pyramid structure for optimizing EUS-based GISTs diagnosis in multi-center analysis with missing label","10.1016/j.compbiomed.2023.107897","Scopus","  Spatiotemporal traffic time series, such as traffic speed data, collected from sensing systems are often incomplete, with considerable corruption and large amounts of missing values. A vast amount of data conceals implicit data structures, which poses significant challenges for data recovery issues, such as mining the potential spatio-temporal correlations of data and identifying abnormal data. In this paper, we propose a Tucker decomposition-based sparse low-rank high-order tensor optimization model (TSLTO) for data imputation and anomaly diagnosis. We decompose the traffic tensor data into low-rank and sparse tensors, and establish a sparse low-rank high-order tensor optimization model based on Tucker decomposition. By utilizing tools of non-smooth analysis for tensor functions, we explore the optimality conditions of the proposed tensor optimization model and design an ADMM optimization algorithm for solving the model. Finally, numerical experiments are conducted on both synthetic data and a real-world dataset: the urban traffic speed dataset of Guangzhou. Numerical comparisons with several representative existing algorithms demonstrate that our proposed approach achieves higher accuracy and efficiency in traffic flow data recovery and anomaly diagnosis tasks. "
" query2","Query2: Query over queries for improving gastrointestinal stromal tumour detection in an endoscopic ultrasound","10.1016/j.compbiomed.2022.106424","Scopus","No abstract available"
" query2","Probabilistic Occlusion Culling using Confidence Maps for High-Quality Rendering of Large Particle Data","10.1109/TVCG.2021.3114788","Scopus","  Establishing robust and accurate correspondences between a pair of images is a long-standing computer vision problem with numerous applications. While classically dominated by sparse methods, emerging dense approaches offer a compelling alternative paradigm that avoids the keypoint detection step. However, dense flow estimation is often inaccurate in the case of large displacements, occlusions, or homogeneous regions. In order to apply dense methods to real-world applications, such as pose estimation, image manipulation, or 3D reconstruction, it is therefore crucial to estimate the confidence of the predicted matches.   We propose the Enhanced Probabilistic Dense Correspondence Network, PDC-Net+, capable of estimating accurate dense correspondences along with a reliable confidence map. We develop a flexible probabilistic approach that jointly learns the flow prediction and its uncertainty. In particular, we parametrize the predictive distribution as a constrained mixture model, ensuring better modelling of both accurate flow predictions and outliers. Moreover, we develop an architecture and an enhanced training strategy tailored for robust and generalizable uncertainty prediction in the context of self-supervised training. Our approach obtains state-of-the-art results on multiple challenging geometric matching and optical flow datasets. We further validate the usefulness of our probabilistic confidence estimation for the tasks of pose estimation, 3D reconstruction, image-based localization, and image retrieval. Code and models are available at https://github.com/PruneTruong/DenseMatching. "
" query2","Query rewrites with views for XML in DB2","https://ieeexplore.ieee.org/abstract/document/4812535/","2009 IEEE 25th …","  We study the complexity of query answering using views in a probabilistic XML setting, identifying large classes of XPath queries -- with child and descendant navigation and predicates -- for which there are efficient (PTime) algorithms. We consider this problem under the two possible semantics for XML query results: with persistent node identifiers and in their absence. Accordingly, we consider rewritings that can exploit a single view, by means of compensation, and rewritings that can use multiple views, by means of intersection. Since in a probabilistic setting queries return answers with probabilities, the problem of rewriting goes beyond the classic one of retrieving XML answers from views. For both semantics of XML queries, we show that, even when XML answers can be retrieved from views, their probabilities may not be computable. For rewritings that use only compensation, we describe a PTime decision procedure, based on easily verifiable criteria that distinguish between the feasible cases -- when probabilistic XML results are computable -- and the unfeasible ones. For rewritings that can use multiple views, with compensation and intersection, we identify the most permissive conditions that make probabilistic rewriting feasible, and we describe an algorithm that is sound in general, and becomes complete under fairly permissive restrictions, running in PTime modulo worst-case exponential time equivalence tests. This is the best we can hope for since intersection makes query equivalence intractable already over deterministic data. Our algorithm runs in PTime whenever deterministic rewritings can be found in PTime. "
" query2","Query2: Query over queries for improving gastrointestinal stromal tumour detection in an endoscopic ultrasound","https://www.sciencedirect.com/science/article/pii/S0010482522011325","Computers in Biology and …","No abstract available"
" query2","Implementation of two semantic query optimization techniques in DB2 universal database","https://www.researchgate.net/profile/Jarek-Gryz/publication/221309776_Implementation_of_Two_Semantic_Query_Optimization_Techniques_in_DB2_Universal_Database/links/0912f51279e7662532000000/Implementation-of-Two-Semantic-Query-Optimization-Techniques-in-DB2-Universal-Database.pdf","VLDB","  We investigate practical algorithms for inconsistency-tolerant query answering over prioritized knowledge bases, which consist of a logical theory, a set of facts, and a priority relation between conflicting facts. We consider three well-known semantics (AR, IAR and brave) based upon two notions of optimal repairs (Pareto and completion). Deciding whether a query answer holds under these semantics is (co)NP-complete in data complexity for a large class of logical theories, and SAT-based procedures have been devised for repair-based semantics when there is no priority relation, or the relation has a special structure. The present paper introduces the first SAT encodings for Pareto- and completion-optimal repairs w.r.t. general priority relations and proposes several ways of employing existing and new encodings to compute answers under (optimal) repair-based semantics, by exploiting different reasoning modes of SAT solvers. The comprehensive experimental evaluation of our implementation compares both (i) the impact of adopting semantics based on different kinds of repairs, and (ii) the relative performances of alternative procedures for the same semantics. "
" query2","Query 2: The sum of values from a normal and a truncated normal distribution (continued)","https://www.jstor.org/stable/1266101","Technometrics","  Low-resource language translation is a challenging but socially valuable NLP task. Building on recent work adapting the Transformer's normalization to this setting, we propose QKNorm, a normalization technique that modifies the attention mechanism to make the softmax function less prone to arbitrary saturation without sacrificing expressivity. Specifically, we apply $\ell_2$ normalization along the head dimension of each query and key matrix prior to multiplying them and then scale up by a learnable parameter instead of dividing by the square root of the embedding dimension. We show improvements averaging 0.928 BLEU over state-of-the-art bilingual benchmarks for 5 low-resource translation pairs from the TED Talks corpus and IWSLT'15. "
" query2","Processing performance on apache pig, apache hive and MySQL cluster","https://ieeexplore.ieee.org/abstract/document/7010600/","Proceedings of International …","  Huge amounts of data being generated continuously by digitally interconnected systems of humans, organizations and machines. Data comes in variety of formats including structured, unstructured and semi-structured, what makes it impossible to apply the same standard approaches, techniques and algorithms to manage and process this data. Fortunately, the enterprise level distributed platform named Hadoop Ecosystem exists. This paper explores Apache Hive component that provides full stack data managements functionality in terms of Data Definition, Data Manipulation and Data Processing. Hive is a data warehouse system, which works with structured data stored in tables. Since, Hive works on top the Hadoop HDSFS, it benefits from extraordinary feature of HDFS including Fault Tolerance, Reliability, High Availability, Scalability, etc. In addition, Hive can take advantage of distributed computing power of the cluster through assigning jobs to MapReduce, Tez and Spark engines to run complex queries. The paper is focused on studying of Hive Data Model and analysis of processing performance done by MapReduce and Tez. "
"query1","Magnesium oxide use and reduced risk of dementia: a retrospective, nationwide cohort study in Taiwan","10.1080/03007995.2017.1385449","Scopus","  We have studied the structure of $^4$He droplets doped with magnesium atoms using density functional theory. We have found that the solvation properties of this system strongly depend on the size of the $^4$He droplet. For small drops, Mg resides in a deep surface state, whereas for large size drops it is fully solvated but radially delocalized in their interior. We have studied the $3s3p$ $^1$P$_1 \leftarrow 3s^2$ $^1$S$_0$ transition of the dopant, and have compared our results with experimental data from laser induced fluorescence (LIF). Line broadening effects due to the coupling of dynamical deformations of the surrounding helium with the dipole excitation of the impurity are explicitly taken into account. We show that the Mg radial delocalization inside large droplets may help reconcile the apparently contradictory solvation properties of magnesium as provided by LIF and electron-impact ionization experiments. The structure of $^4$He drops doped with two magnesium atoms is also studied and used to interpret the results of resonant two-photon-ionization (R2PI) and LIF experiments. We have found that the two solvated Mg atoms do not easily merge into a dimer, but rather form a weakly-bound state due to the presence of an energy barrier caused by the helium environment that keep them some 9.5 \AA{} apart, preventing the formation of the Mg$_2$ molecule. From this observation, we suggest that Mg atoms in $^4$He drops may form, under suitable conditions, a soft ``foam''-like aggregate rather than coalesce into a compact metallic cluster. Our findings are in qualitative agreement with recent R2PI experimental evidences. We predict that, contrarily, Mg atoms adsorbed in $^3$He droplets do not form such metastable aggregates. "
"query1","How different is the care of terminal pancreatic cancer patients in inpatient palliative care units and acute hospital wards? A nationwide population-based study Cancer palliative care","10.1186/s12904-016-0075-x","Scopus","  In this paper we introduce novel Virtual Reality (VR) and Augmented Reality (AR) treatments to improve the psychological well being of patients in palliative care, based on interviews with a clinical psychologist who has successfully implemented VR assisted interventions on palliative care patients in the Hong Kong hospital system. Our VR and AR assisted interventions are adaptations of traditional palliative care therapies which simultaneously facilitate patients communication with family and friends while isolated in hospital due to physical weakness and COVID-19 related restrictions. The first system we propose is a networked, metaverse platform for palliative care patients to create customized virtual environments with therapists, family and friends which function as immersive and collaborative versions of 'life review' and 'reminiscence therapy'. The second proposed system will investigate the use of Mixed Reality telepresence and haptic touch in an AR environment, which will allow palliative care patients to physically feel friends and family in a virtual space, adding to the sense of presence and immersion in that environment. "
"query1","The handbook of mites of economic plants: Identification, bio-ecology and control","No disponible","Scopus","  In this paper, we present a mathematical model for the interaction between honey bees and mites. The dynamics of a mite-infested honey bee colony and the evaluation of the commonly used mite-control strategies (traditional, mechanical and chemical) are studied. The mite-free and mite reproduction numbers are derived using the next generation operator approach. The mathematical analysis of the model reveals that in the absence of mites, the colony survives if the mite-free reproduction number is greater than unity otherwise it goes extinct. Stability and sensitivity analyses of the model reveal that the egg laying rate of the queen bee is key in regulating mite reproduction. Adult bee grooming and hygienic behavior of worker bees have also been shown to play a vital role in reducing parasitism. Using the Volterra-Lyapunov stable matrix approach, the mite-infested equilibrium is confirmed to be globally asymptotically stable when the mite-free reproduction number is greater than unity and the mite reproduction number is greater than unity. It is also shown that varroa mite control strategies that focus on limiting mite-reproduction such as caging the queen bee and using a young queen bee quickly reduces the mite reproduction number to a value less than unity compared to those that are intended to kill the mites. "
"query1","Prime Ministers and Rhetorical Governance","No disponible","Scopus","  We give an elementary introduction, through illustrative examples but without proofs, to one of the basic consequences of the Langlands programme, namely the law governing the primes modulo which a given irreducible integral polynomial splits completely. Some recent results, such as the modularity of elliptic curves over the rationals, or the proof of Serre's conjecture by Khare and Wintenberger, are also illustrated through examples. "
"query1","A hierarchical photo visualization system emphasizing temporal and color-based coherences","10.1007/s11042-010-0700-2","Scopus","  In this paper, we propose a novel model with a hierarchical photo-scene encoder and a reconstructor for the task of album storytelling. The photo-scene encoder contains two sub-encoders, namely the photo and scene encoders, which are stacked together and behave hierarchically to fully exploit the structure information of the photos within an album. Specifically, the photo encoder generates semantic representation for each photo while exploiting temporal relationships among them. The scene encoder, relying on the obtained photo representations, is responsible for detecting the scene changes and generating scene representations. Subsequently, the decoder dynamically and attentively summarizes the encoded photo and scene representations to generate a sequence of album representations, based on which a story consisting of multiple coherent sentences is generated. In order to fully extract the useful semantic information from an album, a reconstructor is employed to reproduce the summarized album representations based on the hidden states of the decoder. The proposed model can be trained in an end-to-end manner, which results in an improved performance over the state-of-the-arts on the public visual storytelling (VIST) dataset. Ablation studies further demonstrate the effectiveness of the proposed hierarchical photo-scene encoder and reconstructor. "
"query1","Query optimization in the presence of foreign functions","https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=169376aa8342eae8c0c5eafcf30f3bf32ea4cb49","VLDB","  Query optimization in relational database management systems (DBMSs) is critical for fast query processing. The query optimizer relies on precise selectivity and cost estimates to effectively optimize queries prior to execution. While this strategy is effective for relational DBMSs, it is not sufficient for DBMSs tailored for processing machine learning (ML) queries. In ML-centric DBMSs, query optimization is challenging for two reasons. First, the performance bottleneck of the queries shifts to user-defined functions (UDFs) that often wrap around deep learning models, making it difficult to accurately estimate UDF statistics without profiling the query. This leads to inaccurate statistics and sub-optimal query plans. Second, the optimal query plan for ML queries is data-dependent, necessitating DBMSs to adapt the query plan on the fly during execution. So, a static query plan is not sufficient for such queries.   In this paper, we present Hydro, an ML-centric DBMS that utilizes adaptive query processing (AQP) for efficiently processing ML queries. Hydro is designed to quickly evaluate UDF-based query predicates by ensuring optimal predicate evaluation order and improving the scalability of UDF execution. By integrating AQP, Hydro continuously monitors UDF statistics, routes data to predicates in an optimal order, and dynamically allocates resources for evaluating predicates. We demonstrate Hydro's efficacy through four illustrative use cases, delivering up to 11.52x speedup over a baseline system. "
"query1","Query-based data pricing","https://dl.acm.org/doi/abs/10.1145/2770870","Journal of the ACM …","  We study the price rigidity of regular and sale prices, and how it is affected by pricing formats (pricing strategies). We use data from three large Canadian stores with different pricing formats (Every-Day-Low-Price, Hi-Lo, and Hybrid) that are located within a 1 km radius of each other. Our data contains both the actual transaction prices and actual regular prices as displayed on the store shelves. We combine these data with two generated regular price series (filtered prices and reference prices) and study their rigidity. Regular price rigidity varies with store formats because different format stores treat sale prices differently, and consequently define regular prices differently. Correspondingly, the meanings of price cuts and sale prices vary across store formats. To interpret the findings, we consider the store pricing format distribution across the US. "
"query1","Discrepant and multi-instance proxies for unsupervised person re-identification","http://openaccess.thecvf.com/content/ICCV2023/html/Zou_Discrepant_and_Multi-Instance_Proxies_for_Unsupervised_Person_Re-Identification_ICCV_2023_paper.html","Proceedings of the IEEE …","  We initiate the study of the effects of non-transparency in decision rules on individuals' ability to improve in strategic learning settings. Inspired by real-life settings, such as loan approvals and college admissions, we remove the assumption typically made in the strategic learning literature, that the decision rule is fully known to individuals, and focus instead on settings where it is inaccessible. In their lack of knowledge, individuals try to infer this rule by learning from their peers (e.g., friends and acquaintances who previously applied for a loan), naturally forming groups in the population, each with possibly different type and level of information regarding the decision rule. We show that, in equilibrium, the principal's decision rule optimizing welfare across sub-populations may cause a strong negative externality: the true quality of some of the groups can actually deteriorate. On the positive side, we show that, in many natural cases, optimal improvement can be guaranteed simultaneously for all sub-populations. We further introduce a measure we term information overlap proxy, and demonstrate its usefulness in characterizing the disparity in improvements across sub-populations. Finally, we identify a natural condition under which improvement can be guaranteed for all sub-populations while maintaining high predictive accuracy. We complement our theoretical analysis with experiments on real-world datasets. "
"query1","Stellar-A Library for API Programming","https://msp.cis.strath.ac.uk/types2025/abstracts/TYPES2025_paper77.pdf","NA","  Developers rely on third-party library Application Programming Interfaces (APIs) when developing software. However, libraries typically come with assumptions and API usage constraints, whose violation results in API misuse. API misuses may result in crashes or incorrect behavior. Even though API misuse is a well-studied area, a recent study of API misuse of deep learning libraries showed that the nature of these misuses and their symptoms are different from misuses of traditional libraries, and as a result highlighted potential shortcomings of current misuse detection tools. We speculate that these observations may not be limited to deep learning API misuses but may stem from the data-centric nature of these APIs. Data-centric libraries often deal with diverse data structures, intricate processing workflows, and a multitude of parameters, which can make them inherently more challenging to use correctly. Therefore, understanding the potential misuses of these libraries is important to avoid unexpected application behavior. To this end, this paper contributes an empirical study of API misuses of five data-centric libraries that cover areas such as data processing, numerical computation, machine learning, and visualization. We identify misuses of these libraries by analyzing data from both Stack Overflow and GitHub. Our results show that many of the characteristics of API misuses observed for deep learning libraries extend to misuses of the data-centric library APIs we study. We also find that developers tend to misuse APIs from data-centric libraries, regardless of whether the API directive appears in the documentation. Overall, our work exposes the challenges of API misuse in data-centric libraries, rather than only focusing on deep learning libraries. Our collected misuses and their characterization lay groundwork for future research to help reduce misuses of these libraries. "
"query1","Bab 13. Pernyataan SQL","https://repository.unikom.ac.id/30754/1/pemrograman%20c++%20builder%2013.pdf","NA","  This is a summary of the proof of BAB conjecture. All material are taken from the two BAB paper in the reference. The aim of this summary is to help reader to understand the more technical side of the proof of BAB. "
"query1","The Codling Moth-A Quandray and a Query1","https://doi.org/10.1093/jee/14.2.156","OpenAlex","  Large Language Models (LLMs) have been successfully used in many natural-language tasks and applications including text generation and AI chatbots. They also are a promising new technology for concept-oriented deep learning (CODL). However, the prerequisite is that LLMs understand concepts and ensure conceptual consistency. We discuss these in this paper, as well as major uses of LLMs for CODL including concept extraction from text, concept graph extraction from text, and concept learning. Human knowledge consists of both symbolic (conceptual) knowledge and embodied (sensory) knowledge. Text-only LLMs, however, can represent only symbolic (conceptual) knowledge. Multimodal LLMs, on the other hand, are capable of representing the full range (conceptual and sensory) of human knowledge. We discuss conceptual understanding in visual-language LLMs, the most important multimodal LLMs, and major uses of them for CODL including concept extraction from image, concept graph extraction from image, and concept learning. While uses of LLMs for CODL are valuable standalone, they are particularly valuable as part of LLM applications such as AI chatbots. "
"query1","The Codling Moth-A Quandray and a Query1","10.1093/jee/14.2.156","CrossRef","  Large Language Models (LLMs) have been successfully used in many natural-language tasks and applications including text generation and AI chatbots. They also are a promising new technology for concept-oriented deep learning (CODL). However, the prerequisite is that LLMs understand concepts and ensure conceptual consistency. We discuss these in this paper, as well as major uses of LLMs for CODL including concept extraction from text, concept graph extraction from text, and concept learning. Human knowledge consists of both symbolic (conceptual) knowledge and embodied (sensory) knowledge. Text-only LLMs, however, can represent only symbolic (conceptual) knowledge. Multimodal LLMs, on the other hand, are capable of representing the full range (conceptual and sensory) of human knowledge. We discuss conceptual understanding in visual-language LLMs, the most important multimodal LLMs, and major uses of them for CODL including concept extraction from image, concept graph extraction from image, and concept learning. While uses of LLMs for CODL are valuable standalone, they are particularly valuable as part of LLM applications such as AI chatbots. "
" query2","Cycle-VQA: A Cycle-Consistent Framework for Robust Medical Visual Question Answering","10.1016/j.patcog.2025.111609","Scopus","No abstract available"
" query2","Progress in artificial intelligence assisted digestive endoscopy diagnosis of digestive system diseases","10.11569/wcjd.v32.i3.171","Scopus","  In recent years, the diagnosis of gastrointestinal (GI) diseases has advanced greatly with the advent of high-tech video capsule endoscopy (VCE) technology, which allows for non-invasive observation of the digestive system. The MisaHub Capsule Vision Challenge encourages the development of vendor-independent artificial intelligence models that can autonomously classify GI anomalies from VCE images. This paper presents CNN architecture designed specifically for multiclass classification of ten gut pathologies, including angioectasia, bleeding, erosion, erythema, foreign bodies, lymphangiectasia, polyps, ulcers, and worms as well as their normal state. "
" query2","Data pyramid structure for optimizing EUS-based GISTs diagnosis in multi-center analysis with missing label","10.1016/j.compbiomed.2023.107897","Scopus","  Spatiotemporal traffic time series, such as traffic speed data, collected from sensing systems are often incomplete, with considerable corruption and large amounts of missing values. A vast amount of data conceals implicit data structures, which poses significant challenges for data recovery issues, such as mining the potential spatio-temporal correlations of data and identifying abnormal data. In this paper, we propose a Tucker decomposition-based sparse low-rank high-order tensor optimization model (TSLTO) for data imputation and anomaly diagnosis. We decompose the traffic tensor data into low-rank and sparse tensors, and establish a sparse low-rank high-order tensor optimization model based on Tucker decomposition. By utilizing tools of non-smooth analysis for tensor functions, we explore the optimality conditions of the proposed tensor optimization model and design an ADMM optimization algorithm for solving the model. Finally, numerical experiments are conducted on both synthetic data and a real-world dataset: the urban traffic speed dataset of Guangzhou. Numerical comparisons with several representative existing algorithms demonstrate that our proposed approach achieves higher accuracy and efficiency in traffic flow data recovery and anomaly diagnosis tasks. "
" query2","Query2: Query over queries for improving gastrointestinal stromal tumour detection in an endoscopic ultrasound","10.1016/j.compbiomed.2022.106424","Scopus","No abstract available"
" query2","Probabilistic Occlusion Culling using Confidence Maps for High-Quality Rendering of Large Particle Data","10.1109/TVCG.2021.3114788","Scopus","  Establishing robust and accurate correspondences between a pair of images is a long-standing computer vision problem with numerous applications. While classically dominated by sparse methods, emerging dense approaches offer a compelling alternative paradigm that avoids the keypoint detection step. However, dense flow estimation is often inaccurate in the case of large displacements, occlusions, or homogeneous regions. In order to apply dense methods to real-world applications, such as pose estimation, image manipulation, or 3D reconstruction, it is therefore crucial to estimate the confidence of the predicted matches.   We propose the Enhanced Probabilistic Dense Correspondence Network, PDC-Net+, capable of estimating accurate dense correspondences along with a reliable confidence map. We develop a flexible probabilistic approach that jointly learns the flow prediction and its uncertainty. In particular, we parametrize the predictive distribution as a constrained mixture model, ensuring better modelling of both accurate flow predictions and outliers. Moreover, we develop an architecture and an enhanced training strategy tailored for robust and generalizable uncertainty prediction in the context of self-supervised training. Our approach obtains state-of-the-art results on multiple challenging geometric matching and optical flow datasets. We further validate the usefulness of our probabilistic confidence estimation for the tasks of pose estimation, 3D reconstruction, image-based localization, and image retrieval. Code and models are available at https://github.com/PruneTruong/DenseMatching. "
" query2","Query rewrites with views for XML in DB2","https://ieeexplore.ieee.org/abstract/document/4812535/","2009 IEEE 25th …","  We study the complexity of query answering using views in a probabilistic XML setting, identifying large classes of XPath queries -- with child and descendant navigation and predicates -- for which there are efficient (PTime) algorithms. We consider this problem under the two possible semantics for XML query results: with persistent node identifiers and in their absence. Accordingly, we consider rewritings that can exploit a single view, by means of compensation, and rewritings that can use multiple views, by means of intersection. Since in a probabilistic setting queries return answers with probabilities, the problem of rewriting goes beyond the classic one of retrieving XML answers from views. For both semantics of XML queries, we show that, even when XML answers can be retrieved from views, their probabilities may not be computable. For rewritings that use only compensation, we describe a PTime decision procedure, based on easily verifiable criteria that distinguish between the feasible cases -- when probabilistic XML results are computable -- and the unfeasible ones. For rewritings that can use multiple views, with compensation and intersection, we identify the most permissive conditions that make probabilistic rewriting feasible, and we describe an algorithm that is sound in general, and becomes complete under fairly permissive restrictions, running in PTime modulo worst-case exponential time equivalence tests. This is the best we can hope for since intersection makes query equivalence intractable already over deterministic data. Our algorithm runs in PTime whenever deterministic rewritings can be found in PTime. "
" query2","Query2: Query over queries for improving gastrointestinal stromal tumour detection in an endoscopic ultrasound","https://www.sciencedirect.com/science/article/pii/S0010482522011325","Computers in Biology and …","No abstract available"
" query2","Implementation of two semantic query optimization techniques in DB2 universal database","https://www.researchgate.net/profile/Jarek-Gryz/publication/221309776_Implementation_of_Two_Semantic_Query_Optimization_Techniques_in_DB2_Universal_Database/links/0912f51279e7662532000000/Implementation-of-Two-Semantic-Query-Optimization-Techniques-in-DB2-Universal-Database.pdf","VLDB","  We investigate practical algorithms for inconsistency-tolerant query answering over prioritized knowledge bases, which consist of a logical theory, a set of facts, and a priority relation between conflicting facts. We consider three well-known semantics (AR, IAR and brave) based upon two notions of optimal repairs (Pareto and completion). Deciding whether a query answer holds under these semantics is (co)NP-complete in data complexity for a large class of logical theories, and SAT-based procedures have been devised for repair-based semantics when there is no priority relation, or the relation has a special structure. The present paper introduces the first SAT encodings for Pareto- and completion-optimal repairs w.r.t. general priority relations and proposes several ways of employing existing and new encodings to compute answers under (optimal) repair-based semantics, by exploiting different reasoning modes of SAT solvers. The comprehensive experimental evaluation of our implementation compares both (i) the impact of adopting semantics based on different kinds of repairs, and (ii) the relative performances of alternative procedures for the same semantics. "
" query2","Query 2: The sum of values from a normal and a truncated normal distribution (continued)","https://www.jstor.org/stable/1266101","Technometrics","  Low-resource language translation is a challenging but socially valuable NLP task. Building on recent work adapting the Transformer's normalization to this setting, we propose QKNorm, a normalization technique that modifies the attention mechanism to make the softmax function less prone to arbitrary saturation without sacrificing expressivity. Specifically, we apply $\ell_2$ normalization along the head dimension of each query and key matrix prior to multiplying them and then scale up by a learnable parameter instead of dividing by the square root of the embedding dimension. We show improvements averaging 0.928 BLEU over state-of-the-art bilingual benchmarks for 5 low-resource translation pairs from the TED Talks corpus and IWSLT'15. "
" query2","Processing performance on apache pig, apache hive and MySQL cluster","https://ieeexplore.ieee.org/abstract/document/7010600/","Proceedings of International …","  Huge amounts of data being generated continuously by digitally interconnected systems of humans, organizations and machines. Data comes in variety of formats including structured, unstructured and semi-structured, what makes it impossible to apply the same standard approaches, techniques and algorithms to manage and process this data. Fortunately, the enterprise level distributed platform named Hadoop Ecosystem exists. This paper explores Apache Hive component that provides full stack data managements functionality in terms of Data Definition, Data Manipulation and Data Processing. Hive is a data warehouse system, which works with structured data stored in tables. Since, Hive works on top the Hadoop HDSFS, it benefits from extraordinary feature of HDFS including Fault Tolerance, Reliability, High Availability, Scalability, etc. In addition, Hive can take advantage of distributed computing power of the cluster through assigning jobs to MapReduce, Tez and Spark engines to run complex queries. The paper is focused on studying of Hive Data Model and analysis of processing performance done by MapReduce and Tez. "
