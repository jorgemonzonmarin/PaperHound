# ğŸ“š PaperHound â€“ Sistema Inteligente para RevisiÃ³n SistemÃ¡tica de Literatura CientÃ­fica

<div style="display: flex; align-items: center; gap: 20px;">
  <img src="PaperHound/assets/Logo.png" alt="PaperHound Logo" width="140"/>
  <p>
    <strong>PaperHound</strong> es una herramienta web desarrollada en Python con Reflex que automatiza, organiza y acelera el proceso de revisiÃ³n sistemÃ¡tica de literatura cientÃ­fica. EstÃ¡ diseÃ±ada para investigadores, doctorandos, ingenieros y equipos de I+D que buscan eficiencia, trazabilidad y rigor metodolÃ³gico en sus revisiones bibliogrÃ¡ficas.
  </p>
</div>



---

## ğŸ¯ Objetivo del Proyecto

El objetivo de PaperHound es **automatizar la bÃºsqueda, clasificaciÃ³n y anÃ¡lisis de artÃ­culos cientÃ­ficos** mediante el uso de consultas complejas (queries), preguntas de revisiÃ³n y modelos de lenguaje como DeepSeek. El sistema extrae artÃ­culos desde mÃºltiples bases de datos, los filtra usando criterios definidos por el usuario y genera una tabla resumen priorizada y justificable.

---

## ğŸ§© Problemas que resuelve

| Problema | CÃ³mo lo soluciona PaperHound |
|---------|-------------------------------|
| ğŸ” La bÃºsqueda manual de artÃ­culos es tediosa y propensa a omisiones | Permite definir queries complejas en lenguaje booleano para realizar bÃºsquedas automÃ¡ticas en Scopus, arXiv, OpenAlex, CrossRef, Semantic Scholar y Google Scholar |
| ğŸ“‚ Es difÃ­cil mantener trazabilidad de queries y criterios de inclusiÃ³n/exclusiÃ³n | Almacena y muestra de forma estructurada el tÃ³pico, las queries y las preguntas en un panel resumen reproducible |
| âœ… El filtrado de papers es subjetivo y consume mucho tiempo | Utiliza un modelo LLM (DeepSeek vÃ­a Ollama) para responder preguntas dicotÃ³micas sobre cada artÃ­culo y justificar cada decisiÃ³n |
| ğŸ“Š No hay forma sencilla de priorizar artÃ­culos relevantes | Genera automÃ¡ticamente un CSV ordenado por nÃºmero de respuestas positivas a los criterios establecidos |
| âš™ï¸ El proceso no es fÃ¡cilmente reutilizable o desplegable | Todo el sistema es portable vÃ­a Docker y puede ejecutarse de forma local o remota sin configuraciÃ³n manual |

---

## ğŸ› ï¸ Estructura General

```text
PaperHound/
â”œâ”€â”€ backend/                # LÃ³gica de estado (queries, preguntas, topic, procesamiento)
â”œâ”€â”€ components/             # Componentes visuales (tablas, selectores, navegaciÃ³n)
â”œâ”€â”€ templates/              # Decoradores para definir pÃ¡ginas
â”œâ”€â”€ assets/ 
â”‚   â”œâ”€â”€ filtro_preguntas/   # Preguntas predefinidas en txt o csv
â”‚   â”œâ”€â”€ papers_encontrados/ # Resultados de los papers encontrados de las bbdd
â”‚   â””â”€â”€ papers_filtrados/   # Resultados generados por el sistema
â”œâ”€â”€ start.sh                # Script de arranque (opcional)
â”œâ”€â”€ Dockerfile              # Imagen para ejecuciÃ³n aislada
â”œâ”€â”€ requirements.txt        # Dependencias
â””â”€â”€ README.md               # (Este documento)
```

---

## ğŸ”„ Flujo del Usuario

1. **IntroducciÃ³n** â€“ En la pÃ¡gina de inicio se presenta el propÃ³sito del sistema.
2. **Definir Queries** â€“ Se introducen consultas complejas para bÃºsqueda de artÃ­culos.
3. **Definir Topic** â€“ Se especifica el objetivo o temÃ¡tica central de la revisiÃ³n.
4. **AÃ±adir Preguntas** â€“ Se redactan preguntas de decisiÃ³n (tipo sÃ­/no) que serÃ¡n evaluadas por deepseek.
5. **Resumen** â€“ Se muestra todo lo definido antes de lanzar el anÃ¡lisis.
6. **Procesamiento** â€“ Se buscan artÃ­culos, se extraen abstracts y se analizan uno por uno mediante un modelo LLM.
7. **VisualizaciÃ³n** â€“ Se muestra una tabla con los artÃ­culos filtrados, ordenados por relevancia, con paginaciÃ³n y color semÃ¡ntico.

---

## âš™ï¸ TecnologÃ­as utilizadas

- **Python 3.12**
- **Reflex** (framework web en Python)
- **Ollama** para ejecutar modelos LLM localmente (por ejemplo, `deepseek`)
- **APIs cientÃ­ficas**:
  - Scopus
  - ArXiv
  - CrossRef
  - OpenAlex
  - Semantic Scholar
  - Google Scholar (vÃ­a `scholarly`)
- **Docker** para ejecuciÃ³n multiplataforma

---

## ğŸ§  LÃ³gica de Procesamiento Inteligente

El anÃ¡lisis semÃ¡ntico se realiza mediante un modelo LLM local (DeepSeek) que responde a cada pregunta definida por el usuario, generando:
- Lista justificada (`1. explained Yes - ...`)
- Lista resumida (`1. summary Yes`)

Esto permite un filtrado trazable y objetivo de los artÃ­culos.

---

## ğŸš€ EjecuciÃ³n con Docker

El `Dockerfile`:
- Instala Python, dependencias y Ollama.
- AÃ±ade la app y los modelos.
- Expone los puertos necesarios (`3000`, `11434`).

### Build y ejecuciÃ³n

```bash
docker build -t paperhound .
docker run -e SCOPUS_API_KEY=valor -v <ruta_local>:/app/assets -p 3000:3000 -p 11434:11434 paperhound
```
---

# ğŸ“§ Contacto
Jorge MonzÃ³n MarÃ­n â€“ jorgemonzonmarin@gmail.com